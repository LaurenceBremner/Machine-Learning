#Load Libaries and datasets
import pandas as pd
import numpy as np
from pandas.plotting import scatter_matrix

#Plotting
import matplotlib.pyplot as plt

#Don't need proprocessing as the built in datasets are already normalised

#Model Selection
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split

#Get confusion matrix and classification report
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

#Classifiers
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import ElasticNet
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

#Load Dataset and create DataFrame
feature_names = ['sepal_length','sepal_width','petal_length','petal_width','flower_type']
df = pd.read_csv('iris.data.csv', names=feature_names)

#Visualise Data
print(df.head())
print(df.shape)
print(df.describe())
print(df.groupby('flower_type').size())

#Create labelled histograms
df.hist()
plt.ylabel('Frequency')
plt.xlabel('Length')
plt.show()

#Create multivariate plots for variable correlations/interactions
scatter_matrix(df)
plt.show()

#Use train test split to split into training, and validation dataset
X = df.values[:,0:4]
Y = df.values[:,4]

test_size = 0.33
seed = 2
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=test_size, random_state=seed)

#Classification Comparison
names = ["Random Forest ", "AdaBoost ", "Decision Tree", "Nearest Neighbors", "Linear SVM SVC", "LDA"]
classifiers = [RandomForestClassifier(), AdaBoostClassifier(), DecisionTreeClassifier(), KNeighborsClassifier(), SVC(), LinearDiscriminantAnalysis()]

#Define scoring system
scoring = 'accuracy'

#Create array of cross validation results
scoring_results = []

#Create array of the classifier names
model_names = []

#Create array of average accuracy for each classifier
averages = []

for name,classifier in list(zip(names,classifiers)):
  kfold = KFold(n_splits=10,random_state=seed)
  cross_val_results=cross_val_score(classifier,X_train,Y_train,cv=kfold,scoring=scoring)
  model_names.append(name)
  scoring_results.append(cross_val_results)
  print("The %s model had a mean accuracy of %f, and a standard deviation of %f" % (name, cross_val_results.mean(), cross_val_results.std()))
  averages.append(cross_val_results.mean())
  
#Plot the models using box and whiskers, and select the best one automatically

#Get index of top performing model. We will use this later to test the top 2 classifiers against each other
index = int(np.argsort(-np.array(averages))[:1])

best_model = classifiers[index]
best_model_name = model_names[index]

mean_score = scoring_results[index].mean()
standard_deviation = scoring_results[index].std()

print("The best model was %s, with a mean accuracy of %f, and a standard deviation of (%f)" % (best_model_name, mean_score, standard_deviation))

#Create a plot of the algorithms

#As well as accuracy we look at recall and f1 score to give a fairer idea of how good the model is
#Get accuracy, recall, and f1 score

#Test model on validation dataset
best_model.fit(X_train,Y_train)
output = best_model.predict(X_test)
print(classification_report(Y_test, output))
print(accuracy_score(Y_test, output))
print(confusion_matrix(Y_test, output))

#This model achieves 100% precision, recall, and f1-score
