#Load Libaries and datasets
import pandas as pd
import numpy as np

#Plotting
from matplotlib import pyplot as plt

#Don't need proprocessing as the built in datasets are already normalised

#Model Selection
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split

#Get confusion matrix and classification report
from sklearn.metrics import classification_report
from sklearn.metrics import confusion matrix
# from sklearn.metrics import scoring

#Classifiers
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClasifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.disciminant_analysis import LinearDiscriminantAnalysis

#Load data and create dataframs
#from sklearn.datasets import load_iris

#Load Data
#iris = load_iris()

#Create DataFrame
#df = pd.DataFrame(iris.data,columns=iris.feature_names)

#Load DataSet
feature_names = ['sepal_length','sepal_width','petal_length','petal_width','flower_type']
#Thus, there are four feature variables and one class variable

#Create dataframe
df = pd.read_csv('iris.data.csv', names=feature_names)

#Visualise Data (first 5 observations)
print(df.head())
print(df.shape)
print(df.describe())
print(df.groupby('flower_type').size())

#Create labelled histograms
df.hist()
plt.ylabel('Frequency')
plt.xlabel('Length')
plt.show()

#Create multivariate plots for variable correlations/interactions
scatter_matrix(df)

#Use train test split to split into training, and validation dataset
X = df.values[:,0:4]
Y = df.values[:,4]

#Random Seed to ensure cross validation is completed on same fold for each model in the case of using KFold 
#(models are tested fairly against one another)
#seed = np.random.seed(0)

test_size = 0.33
seed = 2
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=validation_size, random_state=seed)

#As well as accuracy we look at recall and f1 score to give a fairer idea of how good the model is
#Get accuracy, recall, and f1 score

#Classification Comparison
names = ["Random Forest", "AdaBoost", "Decision Tree", "Nearest Neighbors", "Linear SVM SVC", "LDA"]
classifiers = [RandomForestClassifier(), AdaBoostClassifier(), DecisionTreeClasifier(), KNeighborsClassifier(), SVC(), LinearDiscriminantAnalysis()]

#Define scoring system
scoring = 'accuracy'

#Create tuples of each classifier and its name, and iterate through them
scores = []
model_names = []
for name, classifier zip(names, classifiers):
  kfold = KFold(n_splits=10,random_state=seed)
  cross_val_results = cross_val_score(classifier,X_train,Y_train,cv=kfold,scoring=scoring)
  scores.append(cross_val_results)
  model_names.append(names)
  print("The %s model had a mean accuracy of %f and a standard deviation of (%f)" % (round(cross_val_results.mean(),cross_val_results.std())
 

  
  
  
  
